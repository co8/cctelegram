/**
 * Task 34.4: Integration example showing how to use the complete monitoring system
 * This demonstrates the integration of all SubAgent systems (Alpha, Beta, Gamma) with Delta monitoring
 */

use anyhow::Result;
use std::sync::Arc;
use std::time::Duration;
use tokio::time::sleep;
use tracing::{info, error};

use crate::events::types::{Event, EventType, EventData, ProcessingStatus};
use crate::events::queue_manager::{QueueManager, QueueManagerConfig, Priority};
use crate::telegram::rate_limiter::{RateLimiter, RateLimiterConfig};
use crate::telegram::retry_handler::{RetryHandler, RetryConfig, CircuitBreakerConfig};
use crate::telegram::tracking::{MessageTracker, TrackingConfig, MessageStatus};
use crate::utils::monitoring::TierMonitor;
use crate::utils::monitoring_server::MonitoringServer;
use chrono::Utc;
use uuid::Uuid;

/// Complete integrated monitoring system demonstration
pub struct IntegratedMonitoringDemo {
    message_tracker: Arc<MessageTracker>,
    monitoring_server: Option<MonitoringServer>,
}

impl IntegratedMonitoringDemo {
    /// Initialize the complete monitoring system with all SubAgent components
    pub async fn new() -> Result<Self> {
        info!("ðŸš€ Initializing integrated monitoring system with all SubAgent components");

        // 1. Initialize SubAgent Alpha: Rate Limiter
        info!("ðŸ“Š Initializing SubAgent Alpha (Rate Limiter)...");
        let rate_limiter_config = RateLimiterConfig {
            global_limit: 30,
            per_chat_limit: 1,
            redis_url: Some("redis://localhost:6379".to_string()),
            enable_telemetry: true,
        };

        let rate_limiter = Arc::new(
            RateLimiter::new_in_memory(rate_limiter_config.clone()) // Use in-memory for demo
        );
        info!("âœ… SubAgent Alpha (Rate Limiter) initialized");

        // 2. Initialize SubAgent Beta: Retry Handler
        info!("ðŸ”„ Initializing SubAgent Beta (Retry Handler)...");
        let retry_config = RetryConfig {
            max_attempts: 5,
            initial_delay_ms: 1000,
            max_delay_secs: 30,
            backoff_factor: 2.0,
            enable_jitter: true,
            jitter_range: 0.1,
        };

        let circuit_breaker_config = CircuitBreakerConfig {
            failure_threshold: 5,
            failure_window_secs: 60,
            recovery_timeout_secs: 30,
            success_threshold: 3,
        };

        let retry_handler = RetryHandler::with_config(retry_config, circuit_breaker_config)
            .with_rate_limiter(rate_limiter.clone());
        info!("âœ… SubAgent Beta (Retry Handler) initialized");

        // 3. Initialize SubAgent Gamma: Queue Manager (simplified for demo)
        info!("ðŸ“‹ Initializing SubAgent Gamma (Queue Manager)...");
        // Note: In a real implementation, this would use Redis
        // For demo purposes, we'll create a simplified version
        let queue_config = QueueManagerConfig {
            redis_url: "redis://localhost:6379".to_string(),
            max_workers: 5,
            max_retry_attempts: 3,
            startup_batch_size: 10,
            processing_timeout: Duration::from_secs(30),
            queue_prefix: "cctelegram:queue".to_string(),
        };

        // Create a mock queue manager for demo (would be real in production)
        let queue_manager = Arc::new(
            QueueManager::new(
                queue_config,
                rate_limiter_config,
                retry_config,
                circuit_breaker_config,
            ).await?
        );
        info!("âœ… SubAgent Gamma (Queue Manager) initialized");

        // 4. Initialize Tier Monitor
        info!("ðŸ“ˆ Initializing Tier Monitor...");
        let tier_monitor = Arc::new(TierMonitor::new(None)?);
        info!("âœ… Tier Monitor initialized");

        // 5. Initialize SubAgent Delta: Message Tracker (The Orchestrator)
        info!("ðŸŽ¯ Initializing SubAgent Delta (Message Tracker)...");
        let tracking_config = TrackingConfig {
            max_active_traces: 1000,
            max_completed_traces: 100,
            delivery_rate_alert_threshold: 90.0,
            queue_depth_alert_threshold: 500,
            max_monitoring_overhead_percent: 1.0,
        };

        let message_tracker = Arc::new(MessageTracker::new(
            rate_limiter,
            retry_handler,
            queue_manager,
            tier_monitor.clone(),
            tracking_config,
        ));
        info!("âœ… SubAgent Delta (Message Tracker) initialized");

        // 6. Initialize Monitoring HTTP Server
        info!("ðŸŒ Initializing Monitoring HTTP Server...");
        let monitoring_server = MonitoringServer::new(
            message_tracker.clone(),
            tier_monitor,
            8080,
        );

        info!("ðŸŽ‰ All SubAgent systems initialized successfully!");
        info!("ðŸ“Š Alpha: Rate limiting with Redis backend");
        info!("ðŸ”„ Beta: Retry logic with exponential backoff and circuit breaker");
        info!("ðŸ“‹ Gamma: Queue management with priority handling");
        info!("ðŸŽ¯ Delta: End-to-end message tracking and monitoring dashboard");

        Ok(Self {
            message_tracker,
            monitoring_server: Some(monitoring_server),
        })
    }

    /// Start the monitoring system
    pub async fn start(&mut self) -> Result<()> {
        info!("ðŸš€ Starting integrated monitoring system...");

        // Start monitoring server in background
        if let Some(server) = self.monitoring_server.take() {
            tokio::spawn(async move {
                if let Err(e) = server.start().await {
                    error!("Monitoring server error: {}", e);
                }
            });
        }

        // Give server time to start
        sleep(Duration::from_secs(2)).await;

        info!("âœ… Monitoring system started successfully!");
        info!("ðŸ“Š Dashboard: http://localhost:8080/dashboard/");
        info!("ðŸ“ˆ Metrics: http://localhost:8080/metrics");
        info!("ðŸ¥ Health: http://localhost:8080/health");

        Ok(())
    }

    /// Demonstrate the complete message tracking workflow
    pub async fn demonstrate_message_workflow(&self) -> Result<()> {
        info!("ðŸŽ¬ Demonstrating complete message tracking workflow...");

        // Create a test event
        let event = Event {
            event_id: Uuid::new_v4().to_string(),
            event_type: EventType::TaskCompletion,
            source: "demo".to_string(),
            timestamp: Utc::now(),
            task_id: "demo-task-001".to_string(),
            title: "Task Completion Demonstration".to_string(),
            description: "Demonstrating end-to-end message delivery tracking".to_string(),
            data: EventData::default(),
            correlation_id: None,
            parent_event_id: None,
            retry_count: 0,
            processing_status: ProcessingStatus::Pending,
            priority: None,
            chat_id: Some(123456789),
            processing_metadata: None,
            validation_errors: None,
        };

        // 1. Start tracking the message
        info!("1ï¸âƒ£ Starting message tracking...");
        let correlation_id = self.message_tracker.start_tracking(event, 123456789).await?;
        info!("âœ… Message tracking started with correlation ID: {}", correlation_id);

        // 2. Simulate rate limit check
        info!("2ï¸âƒ£ Simulating rate limit check...");
        self.message_tracker.update_status(&correlation_id, MessageStatus::RateChecking).await?;
        sleep(Duration::from_millis(100)).await;

        // 3. Simulate rate limit wait
        info!("3ï¸âƒ£ Simulating rate limit wait...");
        self.message_tracker.update_status(&correlation_id, MessageStatus::RateWaiting).await?;
        self.message_tracker.add_rate_limit_wait(&correlation_id, Duration::from_millis(500)).await?;
        sleep(Duration::from_millis(500)).await;

        // 4. Simulate retry attempt
        info!("4ï¸âƒ£ Simulating retry attempt...");
        self.message_tracker.update_status(&correlation_id, MessageStatus::Retrying { attempt: 1 }).await?;
        self.message_tracker.add_error(&correlation_id, "Temporary network issue".to_string()).await?;
        sleep(Duration::from_millis(1000)).await;

        // 5. Simulate sending
        info!("5ï¸âƒ£ Simulating message sending...");
        self.message_tracker.update_status(&correlation_id, MessageStatus::Sending).await?;
        sleep(Duration::from_millis(200)).await;

        // 6. Simulate successful delivery
        info!("6ï¸âƒ£ Simulating successful delivery...");
        self.message_tracker.update_status(&correlation_id, MessageStatus::Delivered).await?;

        info!("âœ… Message workflow completed successfully!");
        info!("ðŸ“Š Check the dashboard to see the tracking data");

        // Get final trace
        if let Some(trace) = self.message_tracker.get_trace(&correlation_id).await {
            info!("ðŸ“‹ Final trace status: {:?}", trace.status);
            info!("â±ï¸  Total processing time: {:?}", trace.processing_duration);
            info!("ðŸ”„ Retry attempts: {}", trace.retry_attempts);
            info!("â³ Rate limit waits: {:?}", trace.rate_limit_wait_times);
        }

        Ok(())
    }

    /// Simulate multiple concurrent messages to demonstrate system capacity
    pub async fn simulate_load_test(&self, message_count: usize) -> Result<()> {
        info!("ðŸ‹ï¸â€â™‚ï¸ Starting load test with {} messages...", message_count);

        let mut handles = Vec::new();

        for i in 0..message_count {
            let message_tracker = Arc::clone(&self.message_tracker);
            let handle = tokio::spawn(async move {
                let event = Event {
                    event_id: Uuid::new_v4().to_string(),
                    event_type: EventType::TaskCompletion,
                    source: "load_test".to_string(),
                    timestamp: Utc::now(),
                    task_id: format!("load-test-{}", i),
                    title: format!("Load Test Message {}", i),
                    description: "Load test message".to_string(),
                    data: EventData::default(),
                    correlation_id: None,
                    parent_event_id: None,
                    retry_count: 0,
                    processing_status: ProcessingStatus::Pending,
                    priority: None,
                    chat_id: Some(123456789 + i as i64),
                    processing_metadata: None,
                    validation_errors: None,
                };

                // Start tracking
                if let Ok(correlation_id) = message_tracker.start_tracking(event, 123456789 + i as i64).await {
                    // Simulate quick processing
                    let _ = message_tracker.update_status(&correlation_id, MessageStatus::Sending).await;
                    tokio::time::sleep(Duration::from_millis(50 + (i % 100) as u64)).await;
                    
                    // Random success/failure
                    let status = if i % 10 == 9 {
                        MessageStatus::Failed { reason: "Load test failure".to_string() }
                    } else {
                        MessageStatus::Delivered
                    };
                    let _ = message_tracker.update_status(&correlation_id, status).await;
                }
            });
            handles.push(handle);
        }

        // Wait for all messages to complete
        for handle in handles {
            let _ = handle.await;
        }

        info!("âœ… Load test completed with {} messages", message_count);

        // Get dashboard to show results
        let dashboard = self.message_tracker.get_dashboard().await?;
        info!("ðŸ“Š Load test results:");
        info!("   Total messages: {}", dashboard.delivery_metrics.total_messages);
        info!("   Delivered: {}", dashboard.delivery_metrics.delivered_messages);
        info!("   Failed: {}", dashboard.delivery_metrics.failed_messages);
        info!("   Delivery rate: {:.1}%", dashboard.delivery_metrics.delivery_rate_percent);
        info!("   Average delivery time: {:.1}ms", dashboard.delivery_metrics.average_delivery_time_ms);

        Ok(())
    }

    /// Get current system status
    pub async fn get_system_status(&self) -> Result<()> {
        info!("ðŸ“Š Getting current system status...");

        let dashboard = self.message_tracker.get_dashboard().await?;

        info!("ðŸŽ¯ System Health: {}", dashboard.system_health.overall_status);
        info!("ðŸ“ˆ Delivery Rate: {:.1}%", dashboard.delivery_metrics.delivery_rate_percent);
        info!("ðŸ“‹ Queue Depth: {}", dashboard.delivery_metrics.current_queue_depth);
        info!("ðŸ”„ Active Correlations: {}", dashboard.delivery_metrics.active_correlations);
        info!("âš ï¸  Alerts: {}", dashboard.alerts.len());

        if !dashboard.alerts.is_empty() {
            info!("ðŸš¨ Active Alerts:");
            for alert in &dashboard.alerts {
                info!("   {} - {}: {}", alert.severity, alert.id, alert.message);
            }
        }

        Ok(())
    }
}

/// Main demonstration function
pub async fn run_monitoring_demo() -> Result<()> {
    info!("ðŸŽ‰ Starting CCTelegram Integrated Monitoring Demo");
    info!("ðŸ“‹ This demonstrates the complete integration of:");
    info!("   ðŸ…°ï¸ SubAgent Alpha: Rate Limiter with Redis backend");
    info!("   ðŸ…±ï¸ SubAgent Beta: Retry Handler with circuit breaker");
    info!("   ðŸ†– SubAgent Gamma: Queue Manager with priority handling");
    info!("   ðŸ”º SubAgent Delta: Message Tracker with monitoring dashboard");

    // Initialize the integrated system
    let mut demo = IntegratedMonitoringDemo::new().await?;

    // Start the monitoring system
    demo.start().await?;

    // Demonstrate single message workflow
    demo.demonstrate_message_workflow().await?;

    // Wait a bit to see the results
    sleep(Duration::from_secs(2)).await;

    // Simulate load test
    demo.simulate_load_test(50).await?;

    // Get final system status
    demo.get_system_status().await?;

    info!("ðŸŽ‰ Demo completed successfully!");
    info!("ðŸ“Š Dashboard remains available at: http://localhost:8080/dashboard/");
    info!("ðŸ“ˆ Prometheus metrics at: http://localhost:8080/metrics");
    info!("ðŸ¥ Health check at: http://localhost:8080/health");

    // Keep server running for inspection
    info!("â³ Keeping server running for 60 seconds for inspection...");
    sleep(Duration::from_secs(60)).await;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_integrated_system_initialization() {
        // This is a simplified test - in production you'd use test containers for Redis
        let demo_result = IntegratedMonitoringDemo::new().await;
        
        // The demo might fail due to Redis dependency, but that's expected in test environment
        // In a real test setup, you would use testcontainers-rs or mock Redis
        match demo_result {
            Ok(_) => {
                // If it succeeds (Redis available), that's great
            },
            Err(e) => {
                // If it fails due to Redis, that's expected in test environment
                assert!(e.to_string().contains("Redis") || e.to_string().contains("connection"));
            }
        }
    }
}